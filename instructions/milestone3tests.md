# Milestone 3 â€” Testing & Verification Plan

This document provides a comprehensive plan to fix failing unit tests, create end-to-end tests, and verify OpenAI API integration for the categorization system.

## Overview

**Current Status:**
- âœ… Backend categorization pipeline fully implemented  
- âœ… OpenAI API key configured and working
- âŒ 2 failing unit tests in categorizer package
- âŒ Missing comprehensive end-to-end tests
- âŒ No production verification of LLM integration

**Goals:**
1. Fix the 2 failing unit tests to achieve 100% pass rate
2. Create comprehensive end-to-end test suite  
3. Verify OpenAI API integration works in production environment
4. Establish testing framework for future development

---

## Phase 1: Fix Failing Unit Tests

### Problem Analysis

#### 1. Pass-1 Error Handling Test Failure
**File:** `packages/categorizer/src/pass1.spec.ts:137`
**Issue:** Test expects `'Error during pass1 categorization'` in rationale but gets empty array
**Root Cause:** The catch block in `pass1Categorize` correctly adds error message to rationale, but the test uses a database error that doesn't trigger the outer catch block

#### 2. Pass-2 Description Trimming Test Failure  
**File:** `packages/categorizer/src/pass2_llm.spec.ts:223`
**Issue:** Test expects trimmed description in prompt but gets prompt from cached/previous test
**Root Cause:** Test isolation issue - fetch mock calls are persisting between tests

### Fix Implementation

#### Fix 1: Pass-1 Error Handling Test

**File to modify:** `packages/categorizer/src/pass1.spec.ts`

**Problem:** The test creates a database error scenario but the current implementation only catches errors in the outer try-catch, not database query errors.

**Solution:** Create a test scenario that actually triggers the outer catch block.

```typescript
test('handles errors gracefully', async () => {
  // Create a context that throws during execution
  const errorContext = {
    ...mockContext,
    db: {
      from: () => {
        throw new Error('DB connection failed');
      }
    }
  };

  const tx: NormalizedTransaction = {
    id: 'tx-1' as any,
    orgId: 'test-org-id' as any,
    date: '2024-01-01',
    amountCents: '1000',
    currency: 'USD',
    description: 'Test transaction',
    merchantName: 'Test Merchant',
    source: 'plaid',
    reviewed: false,
    needsReview: false,
    raw: {}
  };

  const result = await pass1Categorize(tx, errorContext);
  
  expect(result.categoryId).toBeUndefined();
  expect(result.confidence).toBeUndefined();
  expect(result.rationale).toContain('Error during pass1 categorization');
});
```

#### Fix 2: Pass-2 Description Trimming Test

**File to modify:** `packages/categorizer/src/pass2_llm.spec.ts`

**Problem:** Test isolation - mock calls are not properly isolated between tests.

**Solution:** Add `beforeEach` to clear mocks and fix test isolation.

```typescript
describe('scoreWithLLM', () => {
  // ... existing setup ...

  beforeEach(() => {
    vi.clearAllMocks();
    (global.fetch as any).mockClear();
  });

  // ... existing tests ...

  test('trims description to 160 characters', async () => {
    const longDescription = 'A'.repeat(200); // 200 character description
    
    (global.fetch as any).mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        choices: [{ message: { content: '{"category_slug":"other_expenses","confidence":0.6,"rationale":"Long description"}' } }],
        usage: { total_tokens: 100 }
      })
    });

    const tx: NormalizedTransaction = {
      id: 'tx-1' as any,
      orgId: 'test-org-id' as any,
      date: '2024-01-01',
      amountCents: '1000',
      currency: 'USD',
      description: longDescription,
      merchantName: 'Test Merchant',
      source: 'plaid',
      reviewed: false,
      needsReview: false,
      raw: {}
    };

    await scoreWithLLM(tx, mockContext);
    
    // Verify that fetch was called with a prompt containing trimmed description
    expect(global.fetch).toHaveBeenCalledTimes(1);
    const fetchCall = (global.fetch as any).mock.calls[0];
    const requestBody = JSON.parse(fetchCall[1].body);
    const prompt = requestBody.messages[1].content;
    
    // Check that the long description was trimmed to 160 chars with ellipsis
    expect(prompt).toContain('A'.repeat(157) + '...');
    expect(prompt).not.toContain('A'.repeat(200)); // Full description should not be present
  });
});
```

### Commands to Execute

```bash
# Navigate to categorizer package
cd packages/categorizer

# Apply the fixes above to the test files
# Then run tests to verify fixes
pnpm test

# Expected result: All tests should pass (12/12)
```

---

## Phase 2: End-to-End Testing

### E2E Test Architecture

**Goal:** Test the complete categorization pipeline from raw transaction to final categorized result.

**Test Scenarios:**
1. Pass-1 only categorization (high confidence)
2. Pass-1 â†’ Pass-2 LLM categorization (low confidence)
3. Corrections workflow and rule generation
4. Embeddings neighbor boost functionality
5. Batch queue processing
6. Error handling and fallbacks

### E2E Test Implementation

#### Create E2E Test File

**File:** `tests/e2e/categorization-pipeline.spec.ts`

```typescript
import { describe, expect, test, beforeAll, afterAll } from 'vitest';
import { createClient } from '@supabase/supabase-js';
import { pass1Categorize } from '@nexus/categorizer/src/pass1';
import { scoreWithLLM } from '@nexus/categorizer/src/pass2_llm';
import { decideAndApply } from '@nexus/services/categorizer/apply';

// Test configuration
const TEST_CONFIG = {
  supabaseUrl: process.env.SUPABASE_URL!,
  supabaseKey: process.env.SUPABASE_SERVICE_ROLE_KEY!,
  openaiApiKey: process.env.OPENAI_API_KEY!,
};

describe('Categorization Pipeline E2E', () => {
  let supabase: any;
  let testOrgId: string;
  let testUserId: string;
  let testTransactionIds: string[] = [];

  beforeAll(async () => {
    // Initialize Supabase client
    supabase = createClient(TEST_CONFIG.supabaseUrl, TEST_CONFIG.supabaseKey);

    // Create test organization and user
    const { data: org } = await supabase
      .from('orgs')
      .insert({ name: 'E2E Test Salon' })
      .select()
      .single();
    testOrgId = org.id;

    const { data: user } = await supabase.auth.admin.createUser({
      email: 'test@example.com',
      password: 'test123',
      email_confirm: true
    });
    testUserId = user.user.id;

    // Add user to org
    await supabase
      .from('user_org_roles')
      .insert({
        user_id: testUserId,
        org_id: testOrgId,
        role: 'owner'
      });
  });

  afterAll(async () => {
    // Clean up test data
    if (testTransactionIds.length > 0) {
      await supabase
        .from('transactions')
        .delete()
        .in('id', testTransactionIds);
    }

    await supabase
      .from('user_org_roles')
      .delete()
      .eq('org_id', testOrgId);

    await supabase
      .from('orgs')
      .delete()
      .eq('id', testOrgId);

    await supabase.auth.admin.deleteUser(testUserId);
  });

  test('Pass-1 high confidence categorization (MCC mapping)', async () => {
    // Create test transaction with hair services MCC
    const { data: transaction } = await supabase
      .from('transactions')
      .insert({
        org_id: testOrgId,
        date: '2024-01-01',
        amount_cents: '15000',
        currency: 'USD',
        description: 'Hair cut and style',
        merchant_name: 'Elite Hair Salon',
        mcc: '7230', // Hair services
        source: 'test',
        raw: {}
      })
      .select()
      .single();

    testTransactionIds.push(transaction.id);

    const ctx = {
      orgId: testOrgId,
      db: supabase,
      analytics: {
        captureEvent: () => {},
        captureException: () => {}
      },
      logger: {
        info: () => {},
        error: () => {}
      }
    };

    // Test Pass-1 categorization
    const pass1Result = await pass1Categorize(transaction, ctx);

    expect(pass1Result.categoryId).toBe('550e8400-e29b-41d4-a716-446655440002'); // Hair Services
    expect(pass1Result.confidence).toBe(0.9);
    expect(pass1Result.rationale).toContain('mcc: 7230 â†’ Hair Services');

    // Test decisioning (should auto-apply)
    await decideAndApply(transaction.id, pass1Result, 'pass1', ctx);

    // Verify transaction was updated
    const { data: updatedTx } = await supabase
      .from('transactions')
      .select('category_id, confidence, needs_review, reviewed')
      .eq('id', transaction.id)
      .single();

    expect(updatedTx.category_id).toBe('550e8400-e29b-41d4-a716-446655440002');
    expect(updatedTx.confidence).toBe(0.9);
    expect(updatedTx.needs_review).toBe(false);
    expect(updatedTx.reviewed).toBe(false);

    // Verify decision audit record
    const { data: decision } = await supabase
      .from('decisions')
      .select('*')
      .eq('tx_id', transaction.id)
      .single();

    expect(decision.source).toBe('pass1');
    expect(decision.confidence).toBe(0.9);
    expect(decision.decided_by).toBe('system');
  });

  test('Pass-1 â†’ Pass-2 LLM categorization (low confidence)', async () => {
    // Create test transaction with unclear categorization
    const { data: transaction } = await supabase
      .from('transactions')
      .insert({
        org_id: testOrgId,
        date: '2024-01-01',
        amount_cents: '5000',
        currency: 'USD',
        description: 'Monthly subscription beauty supplies order',
        merchant_name: 'Beauty Supply Co',
        source: 'test',
        raw: {}
      })
      .select()
      .single();

    testTransactionIds.push(transaction.id);

    const ctx = {
      orgId: testOrgId,
      db: supabase,
      analytics: {
        captureEvent: () => {},
        captureException: () => {}
      },
      logger: {
        info: () => {},
        error: () => {}
      },
      config: {
        openaiApiKey: TEST_CONFIG.openaiApiKey,
        model: 'gpt-4o-mini'
      }
    };

    // Test Pass-1 categorization (should be low/no confidence)
    const pass1Result = await pass1Categorize(transaction, ctx);
    
    // If Pass-1 is not confident enough, try Pass-2
    let finalResult = pass1Result;
    let source: 'pass1' | 'llm' = 'pass1';

    if (!pass1Result.confidence || pass1Result.confidence < 0.85) {
      const llmResult = await scoreWithLLM(transaction, ctx);
      if (llmResult.confidence > (pass1Result.confidence || 0)) {
        finalResult = llmResult;
        source = 'llm';
      }
    }

    // Verify LLM was used and provided reasonable categorization
    expect(source).toBe('llm');
    expect(finalResult.categoryId).toBeDefined();
    expect(finalResult.confidence).toBeGreaterThan(0);
    expect(finalResult.rationale).toContain('LLM:');

    // Test decisioning
    await decideAndApply(transaction.id, finalResult, source, ctx);

    // Verify decision was recorded
    const { data: decision } = await supabase
      .from('decisions')
      .select('*')
      .eq('tx_id', transaction.id)
      .single();

    expect(decision.source).toBe('llm');
    expect(decision.confidence).toBe(finalResult.confidence);
  });

  test('Corrections workflow and rule generation', async () => {
    // Create test transaction
    const { data: transaction } = await supabase
      .from('transactions')
      .insert({
        org_id: testOrgId,
        date: '2024-01-01',
        amount_cents: '8000',
        currency: 'USD',
        description: 'Professional hair products',
        merchant_name: 'Sally Beauty Supply',
        source: 'test',
        raw: {},
        category_id: '550e8400-e29b-41d4-a716-446655440024', // Incorrect initial category
        confidence: 0.6,
        needs_review: true
      })
      .select()
      .single();

    testTransactionIds.push(transaction.id);

    // Simulate correction via API
    const correctionPayload = {
      txId: transaction.id,
      newCategoryId: '550e8400-e29b-41d4-a716-446655440012' // Supplies
    };

    // Test correction logic (simulating API call)
    await supabase
      .from('transactions')
      .update({
        category_id: correctionPayload.newCategoryId,
        reviewed: true,
        needs_review: false
      })
      .eq('id', transaction.id);

    // Insert correction record
    await supabase
      .from('corrections')
      .insert({
        org_id: testOrgId,
        tx_id: transaction.id,
        old_category_id: transaction.category_id,
        new_category_id: correctionPayload.newCategoryId,
        user_id: testUserId
      });

    // Generate rule from correction
    const rulePattern = {
      vendor: 'sally beauty supply' // normalized
    };

    await supabase
      .from('rules')
      .upsert({
        org_id: testOrgId,
        pattern: rulePattern,
        category_id: correctionPayload.newCategoryId,
        weight: 1
      });

    // Verify correction was recorded
    const { data: correction } = await supabase
      .from('corrections')
      .select('*')
      .eq('tx_id', transaction.id)
      .single();

    expect(correction.new_category_id).toBe('550e8400-e29b-41d4-a716-446655440012');

    // Verify rule was created
    const { data: rule } = await supabase
      .from('rules')
      .select('*')
      .eq('org_id', testOrgId)
      .eq('pattern->vendor', 'sally beauty supply')
      .single();

    expect(rule.category_id).toBe('550e8400-e29b-41d4-a716-446655440012');
    expect(rule.weight).toBe(1);

    // Test that future transactions with same vendor get auto-categorized
    const { data: futureTransaction } = await supabase
      .from('transactions')
      .insert({
        org_id: testOrgId,
        date: '2024-01-02',
        amount_cents: '12000',
        currency: 'USD',
        description: 'Hair care products restock',
        merchant_name: 'Sally Beauty Supply LLC', // Slight variation
        source: 'test',
        raw: {}
      })
      .select()
      .single();

    testTransactionIds.push(futureTransaction.id);

    const ctx = {
      orgId: testOrgId,
      db: supabase,
      caches: new Map()
    };

    const futurePass1Result = await pass1Categorize(futureTransaction, ctx);

    expect(futurePass1Result.categoryId).toBe('550e8400-e29b-41d4-a716-446655440012');
    expect(futurePass1Result.confidence).toBeGreaterThan(0.7);
    expect(futurePass1Result.rationale).toContain('vendor:');
  });

  test('Embeddings integration (if implemented)', async () => {
    // This test verifies embeddings neighbor boost functionality
    // Skip if embeddings table is empty (expected in test environment)
    
    const { data: embeddingsCount } = await supabase
      .from('vendor_embeddings')
      .select('id', { count: 'exact' })
      .eq('org_id', testOrgId);

    if (embeddingsCount?.count === 0) {
      console.log('Skipping embeddings test - no embeddings data in test environment');
      return;
    }

    // Test embeddings neighbor boost
    // This would require actual embeddings data to be meaningful
    expect(true).toBe(true); // Placeholder
  });
});
```

#### Create E2E Test Configuration

**File:** `vitest.e2e.config.ts`

```typescript
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    name: 'e2e',
    include: ['tests/e2e/**/*.spec.ts'],
    testTimeout: 30000, // 30 seconds for API calls
    setupFiles: ['tests/e2e/setup.ts'],
    env: {
      NODE_ENV: 'test'
    }
  }
});
```

**File:** `tests/e2e/setup.ts`

```typescript
import { beforeAll } from 'vitest';
import * as dotenv from 'dotenv';

beforeAll(() => {
  // Load environment variables for testing
  dotenv.config();
  
  // Verify required environment variables
  const required = ['SUPABASE_URL', 'SUPABASE_SERVICE_ROLE_KEY', 'OPENAI_API_KEY'];
  
  for (const env of required) {
    if (!process.env[env]) {
      throw new Error(`Missing required environment variable: ${env}`);
    }
  }
});
```

### Commands to Execute

```bash
# Create E2E test structure
mkdir -p tests/e2e

# Create the test files (content above)
# tests/e2e/categorization-pipeline.spec.ts
# tests/e2e/setup.ts  
# vitest.e2e.config.ts

# Install additional dependencies if needed
pnpm add -D @supabase/supabase-js

# Run E2E tests
pnpm vitest run --config vitest.e2e.config.ts

# Expected result: All E2E tests should pass, verifying full pipeline
```

---

## Phase 3: Production OpenAI API Verification

### Real API Integration Test

**Goal:** Verify that the OpenAI integration works correctly in production with real API calls.

#### Create Production Verification Script

**File:** `scripts/verify-openai-integration.ts`

```typescript
#!/usr/bin/env node

import * as dotenv from 'dotenv';
import { scoreWithLLM } from '../packages/categorizer/src/pass2_llm';
import type { NormalizedTransaction } from '@nexus/types';

// Load environment variables
dotenv.config();

// Test scenarios for production verification
const TEST_SCENARIOS = [
  {
    name: 'Hair Services Transaction',
    transaction: {
      id: 'test-1',
      orgId: 'test-org',
      merchantName: 'Elite Hair Salon',
      description: 'Hair cut and style service',
      amountCents: '15000',
      mcc: '7230',
      date: '2024-01-01',
      currency: 'USD',
      source: 'test',
      reviewed: false,
      needsReview: false,
      raw: {}
    } as NormalizedTransaction,
    expectedCategory: 'hair_services'
  },
  {
    name: 'Beauty Supplies Purchase',
    transaction: {
      id: 'test-2', 
      orgId: 'test-org',
      merchantName: 'Sally Beauty Supply',
      description: 'Professional hair care products and tools',
      amountCents: '25000',
      mcc: '5912',
      date: '2024-01-01',
      currency: 'USD',
      source: 'test',
      reviewed: false,
      needsReview: false,
      raw: {}
    } as NormalizedTransaction,
    expectedCategory: 'supplies'
  },
  {
    name: 'Software Subscription',
    transaction: {
      id: 'test-3',
      orgId: 'test-org', 
      merchantName: 'Adobe Creative Cloud',
      description: 'Monthly software subscription',
      amountCents: '2999',
      date: '2024-01-01',
      currency: 'USD',
      source: 'test',
      reviewed: false,
      needsReview: false,
      raw: {}
    } as NormalizedTransaction,
    expectedCategory: 'software'
  }
];

async function verifyOpenAIIntegration() {
  console.log('ðŸ” Verifying OpenAI API Integration...\n');

  if (!process.env.OPENAI_API_KEY) {
    console.error('âŒ OPENAI_API_KEY environment variable not set');
    process.exit(1);
  }

  console.log('âœ… OpenAI API Key found');
  console.log(`ðŸ”‘ Key starts with: ${process.env.OPENAI_API_KEY.slice(0, 10)}...\n`);

  const mockDb = {
    from: () => ({
      select: () => ({
        eq: () => ({
          single: () => Promise.resolve({ data: null, error: null })
        })
      })
    })
  };

  const ctx = {
    orgId: 'test-org',
    db: mockDb,
    config: {
      openaiApiKey: process.env.OPENAI_API_KEY,
      model: 'gpt-4o-mini'
    },
    analytics: {
      captureEvent: (event: string, data: any) => {
        console.log(`ðŸ“Š Analytics Event: ${event}`, data);
      },
      captureException: (error: Error) => {
        console.log(`ðŸš¨ Analytics Exception:`, error.message);
      }
    },
    logger: {
      error: (message: string, error?: any) => {
        console.log(`ðŸ”´ Logger Error: ${message}`, error);
      }
    }
  };

  let successCount = 0;
  let totalCost = 0;

  for (const scenario of TEST_SCENARIOS) {
    console.log(`\nðŸ§ª Testing: ${scenario.name}`);
    console.log(`   Merchant: ${scenario.transaction.merchantName}`);
    console.log(`   Description: ${scenario.transaction.description}`);
    console.log(`   Amount: $${(parseInt(scenario.transaction.amountCents) / 100).toFixed(2)}`);

    try {
      const startTime = Date.now();
      const result = await scoreWithLLM(scenario.transaction, ctx);
      const duration = Date.now() - startTime;

      console.log(`   â±ï¸  Duration: ${duration}ms`);
      console.log(`   ðŸŽ¯ Category: ${result.categoryId}`);
      console.log(`   ðŸ“Š Confidence: ${result.confidence}`);
      console.log(`   ðŸ’­ Rationale: ${result.rationale.join('; ')}`);

      // Estimate cost (rough approximation)
      const estimatedTokens = 150; // Average prompt + response
      const costPer1kTokens = 0.0005; // GPT-4o-mini pricing
      const estimatedCost = (estimatedTokens / 1000) * costPer1kTokens;
      totalCost += estimatedCost;

      if (result.categoryId && result.confidence && result.confidence > 0.5) {
        console.log(`   âœ… SUCCESS: Valid categorization result`);
        successCount++;
      } else {
        console.log(`   âš ï¸  WARNING: Low confidence or missing category`);
      }

    } catch (error) {
      console.log(`   âŒ FAILED: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  console.log(`\nðŸ“ˆ Summary:`);
  console.log(`   âœ… Successful: ${successCount}/${TEST_SCENARIOS.length}`);
  console.log(`   ðŸ’° Estimated Cost: $${totalCost.toFixed(4)}`);
  console.log(`   ðŸ“Š Success Rate: ${((successCount / TEST_SCENARIOS.length) * 100).toFixed(1)}%`);

  if (successCount === TEST_SCENARIOS.length) {
    console.log(`\nðŸŽ‰ All tests passed! OpenAI integration is working correctly.`);
    process.exit(0);
  } else {
    console.log(`\nâš ï¸  Some tests failed. Please check the OpenAI API configuration.`);
    process.exit(1);
  }
}

// Run verification
verifyOpenAIIntegration().catch((error) => {
  console.error('ðŸ’¥ Verification script failed:', error);
  process.exit(1);
});
```

#### Create Edge Function Integration Test

**File:** `scripts/test-edge-functions.ts`

```typescript
#!/usr/bin/env node

import * as dotenv from 'dotenv';

dotenv.config();

async function testEdgeFunction(functionName: string, payload?: any) {
  const supabaseUrl = process.env.SUPABASE_URL;
  const supabaseAnonKey = process.env.SUPABASE_ANON_KEY;

  if (!supabaseUrl || !supabaseAnonKey) {
    throw new Error('Missing Supabase environment variables');
  }

  const url = `${supabaseUrl}/functions/v1/${functionName}`;
  
  console.log(`ðŸš€ Testing Edge Function: ${functionName}`);
  console.log(`   URL: ${url}`);

  try {
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${supabaseAnonKey}`,
        'Content-Type': 'application/json'
      },
      body: payload ? JSON.stringify(payload) : undefined
    });

    console.log(`   Status: ${response.status} ${response.statusText}`);
    
    const data = await response.text();
    console.log(`   Response: ${data.slice(0, 200)}${data.length > 200 ? '...' : ''}`);

    if (response.ok) {
      console.log(`   âœ… SUCCESS`);
      return true;
    } else {
      console.log(`   âŒ FAILED`);
      return false;
    }

  } catch (error) {
    console.log(`   ðŸ’¥ ERROR: ${error instanceof Error ? error.message : 'Unknown error'}`);
    return false;
  }
}

async function testAllEdgeFunctions() {
  console.log('ðŸ” Testing Edge Functions Integration...\n');

  const functions = [
    { name: 'categorize-queue', payload: null },
    { name: 'embeddings-refresh', payload: null }
  ];

  let successCount = 0;

  for (const func of functions) {
    const success = await testEdgeFunction(func.name, func.payload);
    if (success) successCount++;
    console.log(''); // Empty line
  }

  console.log(`ðŸ“ˆ Summary: ${successCount}/${functions.length} edge functions working`);
  
  if (successCount === functions.length) {
    console.log('ðŸŽ‰ All edge functions are accessible!');
  } else {
    console.log('âš ï¸  Some edge functions may not be deployed correctly.');
  }
}

testAllEdgeFunctions().catch(console.error);
```

### Commands to Execute

```bash
# Make scripts executable
chmod +x scripts/verify-openai-integration.ts
chmod +x scripts/test-edge-functions.ts

# Install script dependencies
pnpm add -D tsx

# Test OpenAI integration with real API calls
npx tsx scripts/verify-openai-integration.ts

# Test Edge Functions accessibility
npx tsx scripts/test-edge-functions.ts

# Expected results:
# - OpenAI script should show successful categorizations
# - Edge functions should be accessible (may return errors if no data)
```

---

## Phase 4: Continuous Testing Setup

### GitHub Actions Workflow

**File:** `.github/workflows/categorization-tests.yml`

```yaml
name: Categorization Tests

on:
  push:
    paths:
      - 'packages/categorizer/**'
      - 'services/categorizer/**'
      - 'apps/edge/jobs/**'
  pull_request:
    paths:
      - 'packages/categorizer/**'
      - 'services/categorizer/**'
      - 'apps/edge/jobs/**'

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'
      
      - name: Install dependencies
        run: pnpm install

      - name: Run categorizer unit tests
        run: pnpm --filter @nexus/categorizer test

      - name: Run apply service tests
        run: pnpm test services/categorizer/apply.spec.ts

  openai-integration:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: unit-tests
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install

      - name: Verify OpenAI Integration
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npx tsx scripts/verify-openai-integration.ts
```

### Package.json Scripts

Add these scripts to the root `package.json`:

```json
{
  "scripts": {
    "test:categorization": "pnpm --filter @nexus/categorizer test",
    "test:e2e": "vitest run --config vitest.e2e.config.ts",
    "test:integration": "npx tsx scripts/verify-openai-integration.ts",
    "test:edge-functions": "npx tsx scripts/test-edge-functions.ts",
    "test:all": "pnpm run test:categorization && pnpm run test:e2e && pnpm run test:integration"
  }
}
```

---

## Execution Timeline

### Day 1: Unit Test Fixes
- [ ] Fix Pass-1 error handling test
- [ ] Fix Pass-2 description trimming test  
- [ ] Verify all unit tests pass (12/12)

### Day 2: E2E Test Development
- [ ] Create E2E test structure and configuration
- [ ] Implement Pass-1 â†’ Decision test
- [ ] Implement Pass-1 â†’ Pass-2 â†’ Decision test
- [ ] Implement corrections workflow test

### Day 3: Production Verification
- [ ] Create OpenAI integration verification script
- [ ] Test real API calls with sample transactions
- [ ] Create Edge Functions accessibility test
- [ ] Document cost estimates and rate limits

### Day 4: Continuous Integration
- [ ] Set up GitHub Actions workflow
- [ ] Add package.json test scripts
- [ ] Create testing documentation
- [ ] Establish monitoring and alerting

---

## Success Criteria

### Unit Tests
- âœ… All 12 categorizer unit tests pass
- âœ… No flaky or intermittent test failures
- âœ… Tests run consistently under 10 seconds

### E2E Tests  
- âœ… Complete pipeline test (Pass-1 â†’ Pass-2 â†’ Decision â†’ Apply)
- âœ… Corrections workflow generates and uses rules
- âœ… Database state changes are verified
- âœ… Tests clean up after themselves

### Production Verification
- âœ… OpenAI API responds with valid categorizations
- âœ… Confidence scores are reasonable (> 0.5 for clear transactions)
- âœ… Cost per categorization is under $0.001
- âœ… Edge Functions are accessible and functional

### Quality Metrics
- âœ… Test coverage > 90% for core categorization logic
- âœ… All tests documented with clear expectations
- âœ… Performance benchmarks established
- âœ… Error handling scenarios covered

---

## Risk Mitigation

### API Rate Limits
- **Risk:** OpenAI API rate limiting during tests
- **Mitigation:** Add retry logic and delay between test calls

### Test Data Pollution
- **Risk:** E2E tests affecting production data
- **Mitigation:** Use separate test database or proper cleanup

### Flaky Tests
- **Risk:** Tests failing intermittently due to network issues
- **Mitigation:** Add proper timeouts and retry mechanisms

### Cost Control
- **Risk:** High API costs from testing
- **Mitigation:** Limit test scenarios and use mocks where possible

---

This comprehensive testing plan ensures the categorization system is reliable, performant, and ready for production use. Each phase builds upon the previous one, creating a robust testing foundation for future development.
